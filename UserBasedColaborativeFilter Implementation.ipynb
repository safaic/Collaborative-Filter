{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "import pandas as pd\n",
    "import math \n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from surprise import accuracy\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from surprise import KNNWithMeans, KNNBaseline, KNNBasic, SVDpp, SlopeOne, NMF, NormalPredictor, KNNWithZScore, BaselineOnly, CoClustering, SVD\n",
    "#from surprise.model_SELECTion import cross_validate\n",
    "import pyodbc\n",
    "#!pip install pyodbc\n",
    "#!pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "server = 'CamLaptop'  # Replace with your server name\n",
    "database = 'Foo'  # Replace with your database name\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Establish a connection\n",
    "conn = pyodbc.connect(conn_str) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull training data set from SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute SQL queries\n",
    "query = \"\"\" \n",
    "\t\t\tSELECT ContID, viewed_resources.[user_id], viewed_resources.resource_id,rating, relevant, helpful, presentDifferently, CustID, title, [type],competency,subCompetency from user_feedback \n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\tviewed_resources ON user_feedback.[viewed_resource_id] = viewed_resources.id \n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\t(SELECT [user_id], COUNT(*) AS num_views, ROW_NUMBER() OVER (ORDER BY [user_id] ASC) AS CustID\n",
    "\t\t\tFROM viewed_resources GROUP BY [user_id]) AS A ON A.[user_id] = viewed_resources.[user_id]\n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\tresources_content ON viewed_resources.resource_id = resources_content.id\n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\t(SELECT resource_id, COUNT(*) AS num_views, ROW_NUMBER() OVER (ORDER BY [resource_id] ASC) AS ContID\n",
    "\t\t\tFROM viewed_resources GROUP BY resource_id) AS B ON B.resource_id = viewed_resources.resource_id\n",
    "\n",
    "\t\t\tWHERE EXISTS\n",
    "\n",
    "\t\t\t(SELECT count([user_id]) as cnt, [user_id] from user_feedback inner join viewed_resources \n",
    "\t\t\t ON user_feedback.[viewed_resource_id] = viewed_resources.id group by [user_id] having count([user_id]) > 5) \n",
    "    \t\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "\n",
    "# take query and write output to a dataframe \n",
    "dfo = pd.DataFrame.from_records(cursor.fetchall(), columns=[column[0] for column in cursor.description])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate List of Unique Values for UserID, Type, Competency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate List of Unique Values for UserID, Type, Competency\n",
    "type_List = dfo['type'].unique().tolist()\n",
    "user_List = dfo['CustID'].unique().tolist()\n",
    "competency_List = dfo['competency'].unique().tolist()\n",
    "content_List = dfo['ContID'].unique().tolist()\n",
    "\n",
    "print(competency_List)\n",
    "print(type_List)\n",
    "print(user_List)\n",
    "print(content_List)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training Data Sets For Three Unique Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = dfo[['CustID','competency','rating']]\n",
    "df_type = dfo[['CustID','type','rating']]\n",
    "df_resource = dfo[['CustID','ContID','rating']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Models and Train With User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1)) \n",
    "#Competency Model\n",
    "data_comp = Dataset.load_from_df(df_comp[[\"CustID\", \"competency\", \"rating\"]], reader)\n",
    "trainset = data_comp.build_full_trainset()\n",
    "sim_options = {\n",
    "      \"name\": \"cosine\",\n",
    "      \"user_based\": True,\n",
    "      \"k\" : 20\n",
    "  }\n",
    "  # Create the algorithm\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "  # Train the algorithm on the training set\n",
    "algo.fit(trainset)\n",
    "\n",
    "\n",
    "#Content Type Model\n",
    "data_comp = Dataset.load_from_df(df_type[[\"CustID\", \"type\", \"rating\"]], reader)\n",
    "trainset = data_comp.build_full_trainset()\n",
    "sim_options = {\n",
    "      \"name\": \"cosine\",\n",
    "      \"user_based\": True,\n",
    "      \"k\" : 25\n",
    "  }\n",
    "  # Create the algorithm\n",
    "algo1 = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "  # Train the algorithm on the training set\n",
    "algo1.fit(trainset)\n",
    "\n",
    "#Content Type Model\n",
    "data_comp = Dataset.load_from_df(df_resource[[\"CustID\", \"ContID\", \"rating\"]], reader)\n",
    "trainset = data_comp.build_full_trainset()\n",
    "sim_options = {\n",
    "      \"name\": \"cosine\",\n",
    "      \"user_based\": True,\n",
    "      \"k\" : 20\n",
    "  }\n",
    "  # Create the algorithm\n",
    "algo2 = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "  # Train the algorithm on the training set\n",
    "algo2.fit(trainset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Predictions For Each Model, Content Tyoe, and User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_List = dfo['type'].unique().tolist()\n",
    "user_List = dfo['CustID'].unique().tolist()\n",
    "competency_List = dfo['competency'].unique().tolist()\n",
    "resource_List = dfo['ContID'].unique().tolist()\n",
    "\n",
    "df_resource = dfo[['CustID','resource_id','rating']]\n",
    "\n",
    "#Create Dataframe for predictions \n",
    "dfz = pd.DataFrame(columns=['UserID', 'Competency', 'Rating', 'ValueType'])\n",
    "# Loop over users\n",
    "for users in user_List:\n",
    "    # Loop over competencies\n",
    "    for comp in competency_List:\n",
    "        # Predict the rating for the user and competency\n",
    "        prediction = algo.predict(users, comp)\n",
    "        # Extract the necessary information from the prediction object\n",
    "        uid = prediction.uid\n",
    "        iid = prediction.iid\n",
    "        est = prediction.est\n",
    "        # Append the prediction information to the dataframe\n",
    "        dfz = dfz.append({'UserID': uid, 'Competency': iid, 'Rating': est, 'ValueType': 'Competency'}, ignore_index=True)\n",
    "\n",
    "#Create Dataframe for predictions \n",
    "dfk = pd.DataFrame(columns=['UserID', 'Type', 'Rating', 'ValueType'])\n",
    "for users in user_List:\n",
    "    # Loop over content types\n",
    "    for types in type_List:\n",
    "        # Predict the rating for the user and competency\n",
    "        prediction = algo1.predict(users, types)     \n",
    "        # Extract the necessary information from the prediction object\n",
    "        uid = prediction.uid\n",
    "        iid = prediction.iid\n",
    "        est = prediction.est     \n",
    "        # Append the prediction information to the dataframe\n",
    "        dfk = dfk.append({'UserID': uid, 'Type': iid, 'Rating': est, 'ValueType': \"Type\"}, ignore_index=True)  \n",
    "\n",
    "#Create Dataframe for predictions \n",
    "dfc = pd.DataFrame(columns=['UserID', 'ContentID', 'Rating', 'ValueType'])\n",
    "for users in user_List:\n",
    "    # Loop over content types\n",
    "    for types in resource_List:\n",
    "        # Predict the rating for the user and competency\n",
    "        prediction = algo2.predict(users, types)     \n",
    "        # Extract the necessary information from the prediction object\n",
    "        uid = prediction.uid\n",
    "        iid = prediction.iid\n",
    "        est = prediction.est     \n",
    "        # Append the prediction information to the dataframe\n",
    "        dfc = dfc.append({'UserID': uid, 'ContentID': iid, 'Rating': est, 'ValueType': \"ContentID\"}, ignore_index=True)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and Union Predictions For SQL Injestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFK = dfk.sort_values(by=['UserID','Rating'], ascending=[True,False])\n",
    "DFZ = dfz.sort_values(by=['UserID','Rating'], ascending=[True,False])\n",
    "DFZ['Type'] = DFZ['Competency']\n",
    "DFC = dfc.sort_values(by=['UserID','Rating'], ascending=[True,False])\n",
    "DFC['Type'] = DFC['ContentID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFX = pd.concat([DFK, DFZ, DFC])\n",
    "DFX =DFX.drop(['ContentID', 'Competency'], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Predictions Into SQL Server's Prediction Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(conn_str) \n",
    "cursor = conn.cursor()\n",
    "query = \"\"\" Delete [user_predictions] \"\"\"\n",
    "cursor.execute(query)\n",
    "\n",
    "for index, row in DFX.iterrows():\n",
    "    insert_query = f\"INSERT INTO {'user_predictions'} (UserID, ContID, Rating, ValueType) VALUES (?, ?, ?, ?)\"\n",
    "    cursor.execute(insert_query, row['UserID'], row['Type'], row['Rating'], row['ValueType'])\n",
    "\n",
    "#cursor.execute(query)\n",
    "conn.commit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Prediction Table to Grab Data For Recomendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(conn_str) \n",
    "cursor = conn.cursor()\n",
    "query = \"\"\" \n",
    "\n",
    "select UserID, user_predictions.ContID as ContID, Rating, ValueType from user_predictions LEFT OUTER JOIN (SELECT ContID, CustID from user_feedback \n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\tviewed_resources ON user_feedback.[viewed_resource_id] = viewed_resources.id \n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\t(SELECT [user_id], COUNT(*) AS num_views, ROW_NUMBER() OVER (ORDER BY [user_id] ASC) AS CustID\n",
    "\t\t\tFROM viewed_resources GROUP BY [user_id]) AS A ON A.[user_id] = viewed_resources.[user_id]\n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\tresources_content ON viewed_resources.resource_id = resources_content.id\n",
    "\n",
    "\t\t\tINNER JOIN \n",
    "\n",
    "\t\t\t(SELECT resource_id, COUNT(*) AS num_views, ROW_NUMBER() OVER (ORDER BY [resource_id] ASC) AS ContID\n",
    "\t\t\tFROM viewed_resources GROUP BY resource_id) AS B ON B.resource_id = viewed_resources.resource_id\n",
    "\n",
    "\t\t\tWHERE EXISTS\n",
    "\n",
    "\t\t\t(SELECT count([user_id]) as cnt, [user_id] from user_feedback inner join viewed_resources \n",
    "\t\t\t ON user_feedback.[viewed_resource_id] = viewed_resources.id group by [user_id] having count([user_id]) > 5)) AS A ON CAST(A.ContID AS INT) = UserID AND user_predictions.ContID = CAST(A.ContID AS INT) WHERE ValueType = 'ContentID' AND A.ContID is null\n",
    "\t\t\tUNION \n",
    "\t\t\tselect * from user_predictions where user_predictions.ValueType <> 'ContentID' ORDER BY UserID,ValueType,Rating   desc\n",
    "             \n",
    "               \"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "# take query and write output to a dataframe \n",
    "dfPred1 = pd.DataFrame.from_records(cursor.fetchall(), columns=[column[0] for column in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(conn_str) \n",
    "cursor = conn.cursor()\n",
    "query = \"\"\" \n",
    "\n",
    "select * from user_predictions\n",
    "             \n",
    "               \"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "# take query and write output to a dataframe \n",
    "dfPred = pd.DataFrame.from_records(cursor.fetchall(), columns=[column[0] for column in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPred_Type = dfPred[dfPred['ValueType'] == 'Type']\n",
    "dfPred_Cont = dfPred1[dfPred1['ValueType'] == 'ContentID']\n",
    "dfPred_Comp = dfPred[dfPred['ValueType'] == 'Competency']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab User ID and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,2,5\n",
    "\n",
    "user = int(input())\n",
    "\n",
    "c = dfPred_Comp[dfPred_Comp['UserID'] == user].iloc[0]\n",
    "t = dfPred_Type[dfPred_Type['UserID'] == user].iloc[0]\n",
    "id = dfPred_Cont[dfPred_Cont['UserID'] == user].iloc[0]\n",
    "# Load the image\n",
    "print('Competency:',c.ContID,'\\nType:',t.ContID )\n",
    "if c.ContID == 'SelfAwareness' and t.ContID == 'ASK':\n",
    "    \n",
    "    image_path = r'C:\\Project\\CompRec\\Images\\62192751414d65002e768309.png'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    image_path = r'C:\\Project\\CompRec\\Images\\63695586c9b2193989ea3ab0.png'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print('ContentID#:',id.ContID)\n",
    "if id.ContID == '1':\n",
    "    image_path = r'C:\\Project\\CompRec\\Images\\63193c6899924a3177032b37.png'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "elif id.ContID == '85':\n",
    "\n",
    "    image_path = r'C:\\Project\\CompRec\\Images\\631ce0eb99924a3177037cd0.png'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    image_path = r'C:\\Project\\CompRec\\Images\\63dd6d220966a99f43a1060a.png'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close SQL Connections For Good Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heykiddovenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
